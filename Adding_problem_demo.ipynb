{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv1D, SpatialDropout1D\n",
    "from keras.layers import Activation, Lambda, concatenate\n",
    "from keras.layers import Convolution1D, Dense, Flatten\n",
    "from keras.models import Input, Model\n",
    "import keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(n, seq_length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq_length: Length of the adding problem data\n",
    "        n: # of data in the set\n",
    "    \"\"\"\n",
    "    x_num = np.random.uniform(0, 1, (n, 1, seq_length))\n",
    "    x_mask = np.zeros([n, 1, seq_length])\n",
    "    y = np.zeros([n, 1])\n",
    "    for i in range(n):\n",
    "        positions = np.random.choice(seq_length, size=2, replace=False)\n",
    "        x_mask[i, 0, positions[0]] = 1\n",
    "        x_mask[i, 0, positions[1]] = 1\n",
    "        y[i, 0] = x_num[i, 0, positions[0]] + x_num[i, 0, positions[1]]\n",
    "    x = np.concatenate((x_num, x_mask), axis=1)\n",
    "    x = np.transpose(x, (0, 2, 1))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data_generator(n=50000, seq_length=100)\n",
    "x_test, y_test = data_generator(n=1000, seq_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def channel_normalization(x):\n",
    "    # Normalize by the highest activation\n",
    "    max_values = K.max(K.abs(x), 2, keepdims=True) + 1e-5\n",
    "    out = x / max_values\n",
    "    return out\n",
    "\n",
    "\n",
    "def temporal_block(x, s, i, activation, nb_filters, kernel_size):\n",
    "    original_x = x\n",
    "    conv = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "                  dilation_rate=i, padding='causal',\n",
    "                  name='dilated_conv_%d_tanh_s%d' % (i, s))(x)\n",
    "    if activation == 'norm_relu':\n",
    "        x = Activation('relu')(conv)\n",
    "        x = Lambda(channel_normalization)(x)\n",
    "\n",
    "    x = SpatialDropout1D(0.05)(x)\n",
    "\n",
    "    # 1x1 conv.\n",
    "    x = Convolution1D(nb_filters, 1, padding='same')(x)\n",
    "    res_x = keras.layers.add([original_x, x])\n",
    "    return res_x, x\n",
    "\n",
    "\n",
    "def tcn(num_feat, num_classes, nb_filters,\n",
    "                kernel_size, dilations,max_len,\n",
    "                activation='norm_relu', use_skip_connections=True,\n",
    "                output_slice_index=None,\n",
    "                regression=False):\n",
    "    \"\"\"\n",
    "    dilation_depth : number of layers per stack\n",
    "    nb_stacks : number of stacks.\n",
    "    \"\"\"\n",
    "    input_layer = Input(name='input_layer', shape=(max_len, num_feat))\n",
    "    x = input_layer\n",
    "    x = Convolution1D(nb_filters, kernel_size, padding='causal', name='initial_conv')(x)\n",
    "\n",
    "    skip_connections = []\n",
    "    for s, i in enumerate(dilations):\n",
    "            x, skip_out = temporal_block(x, s, i, activation, nb_filters, kernel_size)\n",
    "            skip_connections.append(skip_out)\n",
    "\n",
    "    if use_skip_connections:\n",
    "        x = keras.layers.add(skip_connections)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Downsample to desired number of output sequences\n",
    "    x = Lambda(lambda tt: tt[:, output_slice_index, :])(x)\n",
    "    print('x.shape=', x.shape)\n",
    "\n",
    "    x = Dense(num_classes)(x)\n",
    "    x = Activation('linear', name='output_dense')(x)\n",
    "    output_layer = x\n",
    "    model = Model(input_layer, output_layer)\n",
    "    adam = optimizers.Adam(lr=0.002, clipnorm=1.)\n",
    "    model.compile(adam, loss='mean_squared_error')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape= (?, 24)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        (None, 100, 2)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "initial_conv (Conv1D)           (None, 100, 24)      360         input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_1_tanh_s0 (Conv1D) (None, 100, 24)      4056        initial_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100, 24)      0           dilated_conv_1_tanh_s0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 100, 24)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 100, 24)      0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 100, 24)      600         spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 100, 24)      0           initial_conv[0][0]               \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_2_tanh_s1 (Conv1D) (None, 100, 24)      4056        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 100, 24)      0           dilated_conv_2_tanh_s1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 100, 24)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 100, 24)      0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 100, 24)      600         spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100, 24)      0           add_1[0][0]                      \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_4_tanh_s2 (Conv1D) (None, 100, 24)      4056        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 100, 24)      0           dilated_conv_4_tanh_s2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 100, 24)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 100, 24)      0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 100, 24)      600         spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 100, 24)      0           add_2[0][0]                      \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_8_tanh_s3 (Conv1D) (None, 100, 24)      4056        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100, 24)      0           dilated_conv_8_tanh_s3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 100, 24)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 100, 24)      0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 100, 24)      600         spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 100, 24)      0           add_3[0][0]                      \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_16_tanh_s4 (Conv1D (None, 100, 24)      4056        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100, 24)      0           dilated_conv_16_tanh_s4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 100, 24)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 100, 24)      0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 100, 24)      600         spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 100, 24)      0           add_4[0][0]                      \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dilated_conv_32_tanh_s5 (Conv1D (None, 100, 24)      4056        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 24)      0           dilated_conv_32_tanh_s5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 100, 24)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 100, 24)      0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 100, 24)      600         spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 100, 24)      0           add_5[0][0]                      \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100, 24)      0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 24)           0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            25          lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_dense (Activation)       (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,321\n",
      "Trainable params: 28,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tcn(output_slice_index=-1,\n",
    "                       num_feat=x_train.shape[2],\n",
    "                       num_classes=1,\n",
    "                       nb_filters=24,\n",
    "                       kernel_size=7,\n",
    "                       dilations=[2**i for i in range(6)],\n",
    "                       max_len=x_train.shape[1],\n",
    "                       activation='norm_relu',\n",
    "                       use_skip_connections=False,\n",
    "                       regression=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.1928 - val_loss: 0.1579\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.0893 - val_loss: 0.0153\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.0221 - val_loss: 0.0064\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.0129 - val_loss: 0.0046\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.0101 - val_loss: 0.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91b9c27da0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.55167333, 0.        ],\n",
       "        [0.35246029, 0.        ],\n",
       "        [0.16584834, 0.        ],\n",
       "        [0.33941679, 0.        ],\n",
       "        [0.71252437, 0.        ],\n",
       "        [0.27922037, 0.        ],\n",
       "        [0.75522695, 0.        ],\n",
       "        [0.12811373, 0.        ],\n",
       "        [0.50160507, 0.        ],\n",
       "        [0.27709846, 0.        ],\n",
       "        [0.31475355, 0.        ],\n",
       "        [0.70910291, 0.        ],\n",
       "        [0.04072749, 1.        ],\n",
       "        [0.3880072 , 0.        ],\n",
       "        [0.5919275 , 0.        ],\n",
       "        [0.14629439, 0.        ],\n",
       "        [0.43198356, 0.        ],\n",
       "        [0.75850719, 0.        ],\n",
       "        [0.66504123, 0.        ],\n",
       "        [0.78722347, 0.        ],\n",
       "        [0.85609317, 0.        ],\n",
       "        [0.11388875, 0.        ],\n",
       "        [0.12272511, 0.        ],\n",
       "        [0.01525723, 0.        ],\n",
       "        [0.9407971 , 0.        ],\n",
       "        [0.19421055, 0.        ],\n",
       "        [0.46345692, 0.        ],\n",
       "        [0.09522939, 0.        ],\n",
       "        [0.73178341, 0.        ],\n",
       "        [0.05138945, 0.        ],\n",
       "        [0.13515224, 0.        ],\n",
       "        [0.67213901, 0.        ],\n",
       "        [0.03858412, 0.        ],\n",
       "        [0.58576859, 0.        ],\n",
       "        [0.40613731, 0.        ],\n",
       "        [0.0092247 , 0.        ],\n",
       "        [0.75590947, 0.        ],\n",
       "        [0.35184038, 0.        ],\n",
       "        [0.47614309, 0.        ],\n",
       "        [0.06483364, 0.        ],\n",
       "        [0.1046515 , 0.        ],\n",
       "        [0.45092879, 0.        ],\n",
       "        [0.32822174, 0.        ],\n",
       "        [0.93842389, 0.        ],\n",
       "        [0.17199844, 0.        ],\n",
       "        [0.78662531, 0.        ],\n",
       "        [0.58209848, 0.        ],\n",
       "        [0.04668029, 0.        ],\n",
       "        [0.12608144, 0.        ],\n",
       "        [0.71014277, 0.        ],\n",
       "        [0.37228142, 0.        ],\n",
       "        [0.37421256, 0.        ],\n",
       "        [0.13550952, 0.        ],\n",
       "        [0.00908864, 0.        ],\n",
       "        [0.40199535, 0.        ],\n",
       "        [0.04046015, 0.        ],\n",
       "        [0.92679356, 0.        ],\n",
       "        [0.85214728, 0.        ],\n",
       "        [0.32222399, 0.        ],\n",
       "        [0.52549107, 0.        ],\n",
       "        [0.81605906, 0.        ],\n",
       "        [0.30057729, 0.        ],\n",
       "        [0.40733013, 0.        ],\n",
       "        [0.88775546, 0.        ],\n",
       "        [0.63359001, 0.        ],\n",
       "        [0.00132871, 1.        ],\n",
       "        [0.02598016, 0.        ],\n",
       "        [0.38883666, 0.        ],\n",
       "        [0.51790871, 0.        ],\n",
       "        [0.45903318, 0.        ],\n",
       "        [0.29258532, 0.        ],\n",
       "        [0.5920269 , 0.        ],\n",
       "        [0.03598678, 0.        ],\n",
       "        [0.34843025, 0.        ],\n",
       "        [0.17087331, 0.        ],\n",
       "        [0.33761592, 0.        ],\n",
       "        [0.96233561, 0.        ],\n",
       "        [0.19811053, 0.        ],\n",
       "        [0.25417886, 0.        ],\n",
       "        [0.554763  , 0.        ],\n",
       "        [0.13556152, 0.        ],\n",
       "        [0.8497817 , 0.        ],\n",
       "        [0.13022839, 0.        ],\n",
       "        [0.44114764, 0.        ],\n",
       "        [0.33510472, 0.        ],\n",
       "        [0.48612295, 0.        ],\n",
       "        [0.83965209, 0.        ],\n",
       "        [0.76860745, 0.        ],\n",
       "        [0.00266097, 0.        ],\n",
       "        [0.52828978, 0.        ],\n",
       "        [0.90493174, 0.        ],\n",
       "        [0.73621439, 0.        ],\n",
       "        [0.31689194, 0.        ],\n",
       "        [0.91986401, 0.        ],\n",
       "        [0.80537591, 0.        ],\n",
       "        [0.55571855, 0.        ],\n",
       "        [0.01036733, 0.        ],\n",
       "        [0.15605726, 0.        ],\n",
       "        [0.51738812, 0.        ],\n",
       "        [0.18636745, 0.        ]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[10:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04831929]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_test[10:11])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042056199999999995"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.04072749+0.00132871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
